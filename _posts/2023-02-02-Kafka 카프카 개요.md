---
title: Kafka 생태계
categories: Kafka
---

# Kafka

### **데브원영**님의 카프카 강의를 바탕으로 공부한 내용을 정리하였습니다!

카프카를 최초로 고안한 개발자 중 한명 : 제이 크랩스 (Jay Kreps)

- 궁금한 내용
    - 세그먼트의 compact 가 동작할 때 키를 기준으로 가장 오래된 레코드만 남긴다고 하는데 여기서 말하는 key는 메세지키가 아닌 카프카가 만든 키인것인가??
    - 컨슈머가 poll() 를 호출하여 여러 레코드에 대해 병렬 처리를 진행할 때 큰 오프셋에 대한 레코드는 정상 처리되서 커밋되고 더 낮은 오프셋을 가진 레코드는 처리를 실패해서 커밋되지 않았을 경우 다음 레코드를 읽을때의 동작은 어떻게 되는 것인가??

---

# 특징

1. 높은 처리량
    1. 파티션
2. 확장성
    1. 클러스터
    2. 브로커
3. 영속성
    1. 파일시스템
    2. 페이지 캐시 메모리 영역
4. 고가용성
    1. 클러스터
    2. 브로커 데이터 복제

---

# 데이터 레이크 아키텍쳐

1. 초기 빅데이터 플랫폼
    1. 소스 애플리케이션 → 원천 데이터 → 파생 데이터 → 서빙데이터 → 클라이언트
2. 람다 아키텍쳐
    1. 소스 애플리케이션 → 배치 레이어 → 서빙 레이어 → 클라이언트
    2. 소스 애플리케이션 → 스피드 레이어 → 클라이언트
        1. 카프카는 스피드 레이어에 위치함
3. 카파 아키텍쳐
    1. 소스 애플리케이션 → 스피드 레이어 → 서빙 레이어 → 클라이언트
4. 스트리밍 데이터 레이크
    1. 카파 아키텍쳐에서 서빙 레이어를 제거
    2. 카프카에서 스트리밍 데이터 레이크를 달성하기위해 티어트 스토리지 방식을 개발중
    

---

# 카프카 생태계

1. producer
    - 이벤트 생성 애플리케이션
2. consumer
    - 이벤트 처리 애플리케이션
3. connect
    - 데이터 파이프라인을 운영하는 툴
    - source - producer 역할
        - 타 플랫폼을 소스로 하는 연동 (mysql, aws s3, etc..)
        - 데이터를 가져와서 토픽에 넣음
    - sync - consumer 역할
        - 특정 대상에 데이터 싱크 (jdbc, elasticsearch, etc..)
        - 토픽의 데이터를 타켓 애플리케이션에 넣음
4. kafka cluster
    - 카프카 브로커의 군집 단위
5. streams
    - 토픽의 데이터를 프로세싱하여 다시 토픽을 생성