---
title: 데이터 전처리
categories: Data
---
데이터 전처리에 대해 학습한 전반적인 내용을 간략히 정리합니다.

### 1. 데이터 전처리

데이터 전처리란 데이터를 분석 및 처리에 적합한 형태로 만드는 과정을 총칭한다.

또한 데이터 전처리는 데이터 분석 및 처리 과정에서 중요한 단계이고 데이터 분석, 데이터 마이닝, 머신러닝 프로젝트에 적용한다. 그리고 일반적으로 데이터는 비어있는 부분이 있거나 정합성이 맞지 않는 경우가 있기 때문에 품질이 낮은 데이터로는 좋은 결과를 얻기 어렵다.

그리고 데이터 과학자들이 가장 많은 시간을 소요하는 일이기도 하다.

- 데이터 분석 step
    1. 데이터 `선택` 
    2. 목표 데이터 `전처리` 
    3. 전처리된 데이터 `변환` 
    4. 변환된 데이터 `데이터마이닝` 
    5. 패턴 `해석과 평가`

### 2. 데이터 품질

완변학 데이터를 얻는다는 것은 실제로는 너무 어려운 일이라고 한다.

- 데이터 품질을 저해하는 주요 요인으로는 크게 측정 오류와 수집 과정에서 발생하는 오류로 나눌 수 있다.
    - 측정 오류 : 사람의 실수로 잘못된 단위로 기록을 하거나 측정 장비 자체의 한계 등 측정 과정에서 발생하는 오류
    - 수집 과정 오류 : 데이터의 손실, 중복 등의 문제로 발생하는 오류
- GIGO (Garbage In Garbage Out)
    - 입력 데이터에 따라 결과의 품질이 결정된다. (만약 쓰레기와 같은 데이터가 들어온다면 결과도 쓰레기일 것이기에..)
        ![GIGO.png](/images/data/GIGO.png)
        ( 출처 : [Link](https://delpha.io/impacts-of-data-quality/) )
        
- 잡음
    - 측정 과정에서 무작위로 발생하여 측정값의 에러를 발생시키는 것이다
    - 실제 데이터는 매끈한 형태의 시계열 데이터였지만 측정 과정에서 잡음이 포함됨으로 인해 실제 값과 다른 데이터를 얻게 되어 실제 데이터의 형태를 잃어버릴 수도 있다

이 외에도 다양한 데이터 품질 저해 요인이 있다. (아티팩트, 정밀도, 바이어스, 정확도, 이상치, 결측치, 모순, 불일치, 중복 등)

### 3. 데이터 전처리 단계

- **데이터 수집** - `분석이나 학습에 필요한 데이터를 부분 혹은 전체를 수집하는 작업`
    - 데이터 처리 분석 및 모델 생성의 첫 과정이다.
    - 문제를 식별하고 탐색함으로써 정보 수집 시기 및 방법을 결정한다.
    - 목적과 목표가 되는 정보를 수집하고 측정하기 위해 명확한 정의가 필요하다.
    - Web, Mobile, IoT, Social 등 다양한 요소로 부터 데이터를 수집한다.  
  
- 데이터 정제 - `비어있는 데이터나 잡음, 모순된 데이터 등을 정합성이 맞도록 교정하는 작업`
    - 데이터를 활용할 수 있도록 만드는 과정이다.
    - 데이터의 누락값, 불일치, 오류의 수정을 거친다.
    - 컴퓨터가 읽을 수 없는 요소를 제거한다.
    - 숫자나 날짜 등의 형식에 대해 일관성을 유지한다.
    - 적합한 파일 포맷으로 변환한다.
    ![데이터 정제](/images/data/데이터정제.png)
    ( 출처 : [Link](https://www.dataentryoutsourced.com/blog/cxos-guide-to-marketing-and-sales-data-cleansing-and-enrichment/) )  
  
- **데이터 통합** - `여러 개의 데이터베이스, 데이터 집합 또는 파일을 통합하는 작업`
    - 서로 다른 출처의 여러 데이터를 결합한다.
    - 서로 다른 데이터 세트가 호환이 가능하도록 통합한다.
    - Linked 데이터의 핵심 목표 중 하나는 데이터 통합을 완전히 또는 거의 완전히 자동화 하는 것이다.
    ![데이터 통합](/images/data/데이터통합.png)
    ( 출처 : [Link](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.tippersvintageplates.co.uk%2Fhttp%2Fhor.happyvalentinesday2020.online%2FHealth-Care-Data-Integration-11b8.html&psig=AOvVaw1eiwgh7gkAPFuC-uG__MpU&ust=1693386448484000&source=images&cd=vfe&opi=89978449&ved=0CBAQjRxqFwoTCIDswZ_CgYEDFQAAAAAdAAAAABAx) )  
  
- **데이터 축소** - `샘플링, 차원축소, 특징 선택 및 추출을 통해 데이터 크기를 줄이는 작업`
    - 일반적으로 데이터는 매우 크기 때문에 대용량 데이터에 대한 복잡한 데이터 분석은 실행하기 어렵거나 불가능한 경우가 많다.
    - 데이터 축소는 원래 용량 기준보다 작은 양의 데이터 표현 결과를 얻게 되더라도 원 데이터의 완결성을 유지하기 위해 사용한다.
    - 데이터를 축소하면 데이터 분석 시 좀 더 효과적이고 원래 데이터와 거의 동일한 분석 결과를 얻어낼 수 있는 장점이 생긴다.
    ![데이터 축소](/images/data/데이터축소.png)
    ( 출처 : [Link](https://www.cohesity.com/blogs/cohesity-data-reduction-lock-stock-barrel) )  
  
- **데이터 변환** - `데이터를 정규화, 이산화 또는 집계를 통해 변환하는 작업`
    - 데이터를 한 형식이나 구조에서 다른 형식이나 구조로 변환한다.
    - 원본 데이터와 대상 데이터간에 필요한 데이터 변경 내용을 기반으로 데이터 변환이 간단하거나 복잡할 수 있다.
    - 데이터 변환은 일반적으로 수동 및 자동 단계가 혼합되어 수행된다.
    - 데이터 변환에 사용되는 도구 및 기술은 변환되는 데이터의 형식, 구조, 복잡성 및 볼륨에 따라 크게 다를 수 있다.  

p.s. 그림으로 보는 데이터 전처리 기법
![그림으로 보는 데이터 전처리](/images/data/datapainting.png)